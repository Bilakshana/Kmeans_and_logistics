# -*- coding: utf-8 -*-
"""Classification_with_Kmeans_logistics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q9QUE7xGjrpl-h-xftHIcqVt40VjKmjG
"""

# ðŸ“¦ Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, classification_report
from scipy.stats import mode
import joblib

# ðŸ“‚ Load the dataset
cell_df = pd.read_csv('sample_data/cell_samples.csv')
print("âœ… Dataset loaded successfully!")

# ðŸ” Initial exploration
print("Shape:", cell_df.shape)
print("Class distribution:\n", cell_df['Class'].value_counts())

# ðŸ“Š Visualize data: Clump vs Uniformity of Cell Size
benign_df = cell_df[cell_df['Class'] == 2][:200]
malignant_df = cell_df[cell_df['Class'] == 4][:200]

axes = benign_df.plot(kind='scatter', x='Clump', y='UnifSize', color='blue', label='Benign')
malignant_df.plot(kind='scatter', x='Clump', y='UnifSize', color='red', label='Malignant', ax=axes)

plt.title("Cell Samples: Clump vs. Uniformity of Cell Size")
plt.xlabel("Clump Thickness")
plt.ylabel("Uniformity of Cell Size")
plt.grid(True)
plt.show()

# ðŸ§¹ Data Cleaning: Remove rows with non-numeric BareNuc values and fix warning
cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]
cell_df.loc[:, 'BareNuc'] = cell_df['BareNuc'].astype(int)

# ðŸŽ¯ Feature selection
features = ['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',
            'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']
X = cell_df[features].values
y = cell_df['Class'].values

# ðŸ”€ Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)

# ðŸ¤– Model training with K-Means clustering
kmeans = KMeans(n_clusters=2, random_state=4)
kmeans.fit(X_train)

# Predict cluster labels for test set
cluster_labels = kmeans.predict(X_test)

# Map clusters to actual class labels based on training data
mapped_labels = np.zeros_like(cluster_labels)
for i in range(2):
    mask = (kmeans.labels_ == i)
    if np.sum(mask) > 0:
        common_label = mode(y_train[mask]).mode.item()  # fixed here using .item()
        mapped_labels[cluster_labels == i] = common_label

# ðŸ§¾ Evaluation
accuracy = accuracy_score(y_test, mapped_labels)
print("\nðŸ“Š Classification Report:\n", classification_report(y_test, mapped_labels))
print(f"âœ… K-Means Model Accuracy: {accuracy * 100:.2f}%")

# ðŸ’¾ Save the trained model
joblib.dump(kmeans, 'kmeans_cell_classifier.joblib')
print("ðŸ’¾ Model saved as 'kmeans_cell_classifier.joblib'")

